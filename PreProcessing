# FOR NULL VALUES
# Get names of columns with missing values
missingColls = [col for col in X_train.columns if X_train[col].isna().any()]

# Drop columns in training and validation data
reduced_X_train = X_train.drop(missingColls, axis = 1)
reduced_X_valid = X_valid.drop(missingColls, axis = 1)

#Imputation
from sklearn.impute import SimpleImputer

Imputer = SimpleImputer()
imputed_X_train = pd.DataFrame(Imputer.fit_transform(X_train))
imputed_X_valid = pd.DataFrame(Imputer.transform(X_valid))

# Imputation removed column names; put them back
imputed_X_train.columns = X_train.columns
imputed_X_valid.columns = X_valid.columns

# FOR CATEGORICAL DATA

# Get number of unique entries in each column with categorical data
object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))
d = dict(zip(object_cols, object_nunique))

# Print number of unique entries by column, in ascending order
sorted(d.items(), key=lambda x: x[1])




# Drop columns in training and validation data
drop_X_train = X_train.select_dtypes(exclude = ["object"])
drop_X_valid = X_valid.select_dtypes(exclude = ["object"])




# Ordinal Encoding
# Categorical columns in the training data
object_cols = [col for col in X_train.columns if X_train[col].dtype == "object"]

# Columns that can be safely ordinal encoded
good_label_cols = [col for col in object_cols if 
                   set(X_valid[col]).issubset(set(X_train[col]))]
        

# Problematic columns that will be dropped from the dataset
bad_label_cols = list(set(object_cols)-set(good_label_cols))
print('Categorical columns that will be ordinal encoded:', good_label_cols)
print('\nCategorical columns that will be dropped from the dataset:', bad_label_cols)

from sklearn.preprocessing import OrdinalEncoder

# Drop categorical columns that will not be encoded
label_X_train = X_train.drop(bad_label_cols, axis=1)
label_X_valid = X_valid.drop(bad_label_cols, axis=1)

# Apply ordinal encoder 
OEncoder = OrdinalEncoder()
label_X_train[good_label_cols] = OEncoder.fit_transform(label_X_train[good_label_cols])
label_X_valid[good_label_cols] = OEncoder.transform(label_X_valid[good_label_cols])




# ONE-HOT ENCODING

# Columns that will be one-hot encoded
low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]

# Columns that will be dropped from the dataset
high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))

print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)
print('\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)



from sklearn.preprocessing import OneHotEncoder

# Drop the columns with too high cardinality
drp_X_train = X_train.drop(high_cardinality_cols, axis = 1)
drp_X_valid = X_valid.drop(high_cardinality_cols, axis = 1)

# Train OHEncoder on the data
OHEncoder = OneHotEncoder(handle_unknown = "ignore", sparse = False)
OH_cols_train = pd.DataFrame(OHEncoder.fit_transform(drp_X_train[low_cardinality_cols]))
OH_cols_valid = pd.DataFrame(OHEncoder.transform(drp_X_valid[low_cardinality_cols]))

# One-hot encoding removed index; put it back
OH_cols_train.index = drp_X_train.index
OH_cols_valid.index = drp_X_valid.index

# Remove categorical columns (will replace with one-hot encoding)
num_X_train = drp_X_train.drop(low_cardinality_cols, axis=1)
num_X_valid = drp_X_valid.drop(low_cardinality_cols, axis=1)

OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1) # Your code here
OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1) # Your code here

# Make sure that every feature is in string form
OH_X_train.columns = OH_X_train.columns.astype(str)
OH_X_valid.columns = OH_X_valid.columns.astype(str)
